# -*- coding: utf-8 -*-
"""Кошки_VS_Собаки_с_расширением_изображений.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j6b5N1dnP2zmfKfsQ0RqBy9xCzP-yIWP
"""



"""## Кошки VS Собаки: классификация изображений с расширением

В этой обучающей части мы обсудим то, каким образом можно классифицировать изображения кошек и собак. Мы разработаем классификатор изображений с использованием `tf.keras.Sequential`-модели, а для загрузки данных воспользуемся `tf.keras.preprocessing.image.ImageDataGenerator`.

### Идеи, которые будут затронуты в этой части:

Мы получим практический опыт разработки классификатора и разовьём интуитивное понимание следующих концепций:

1.   Построение модели потока данных (*data input pipelines*) с использованием `tf.keras.preprocessing.image.ImageDataGenerator`-класса (Каким образом эффективно работать с данными на диске взаимодействуя с моделью?)
2.  Переобучение - что это такое и как его определить?
3. Расширение данных (data augmentation) и метод исключений (dropout) - ключевые техники в борьбе с переобучением в задач распознавания образов, которые мы внедрим в наш процесс обучения модели.

#### Мы будем следовать основному подходу при разработке моделей машинного обучения:

1. Исследовать и понять данные
2. Настроить поток входных данных
3. Построить модель
4. Обучить модель
5. Протестировать модель
6. Улучшить модель / Повторить процесс

**Перед тем как мы начнем...**

Перед тем как запускать код в редакторе, рекомедуем сбросить все настройки в **Runtime -> Reset all** в верхнем меню. Подобное действие позволит избежать проблем с нехваткой памяти, если параллельно вы работали или работаете с несколькими редакторами.

# Импортирование пакетов

Давайте начнём с импорта нужных пакетов:

*   `os` - чтение файлов и структуры директорий;
*   `numpy` - для некоторых матричных операций вне TensorFlow;
* `matplotlib.pyplot` - построение графиков и отображение изображений из тестового и валидационного набора данных.
"""

from __future__ import absolute_import, division, print_function, unicode_literals

import os
import matplotlib.pyplot as plt
import numpy as np

"""Импортируем `TensorFlow`:"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator

import logging
logger = tf.get_logger()
logger.setLevel(logging.ERROR)

"""# Загрузка данных

Разработку нашего классификатора мы начинаем с загрузки набора данных. Набор данных, который мы используем представляет собой отфильтрованную версию набора данных [Собаки vs Кошки](https://www.kaggle.com/c/dogs-vs-cats/data) с сервиса Kaggle (в конце концов именно этот набор данных предоставляется Microsoft Research).

В прошлом CoLab мы с вами использовали набор данных из самого [TensorFlow Dataset](https://www.tensorflow.org/datasets) модуля, который оказывается крайне удобным для работы и тестирования. В этом CoLab однако, мы воспользуемся классом `tf.keras.preprocessing.image.ImageDataGenerator` для чтения данных с диска. Поэтому предварительно нам необходимо загрузить набор данных Собаки VS Кошки и разархивировать его.
"""

_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)

"""Набор данных, который мы загрузили, имеет следующую структуру:

<pre style="font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;" >
<b>cats_and_dogs_filtered</b>
|__ <b>train</b>
    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...]
    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]
|__ <b>validation</b>
    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...]
    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]
</pre>

Чтобы получить полный список директор можно воспользоваться следующей командой:
"""

zip_dir_base = os.path.dirname(zip_dir)
!find $zip_dir_base -type d -print

"""Теперь присвоим переменным корректные пути к директориям с наборами данных для тренировки и валидации:"""

base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')
validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

"""#### Разбираемся с данными и их структурой

Давайте посмотрим сколько же у нас изображений кошек и собак в тестовом и валидационном наборах данных (директориях).
"""

num_cats_tr = len(os.listdir(train_cats_dir))
num_dogs_tr = len(os.listdir(train_dogs_dir))

num_cats_val = len(os.listdir(validation_cats_dir))
num_dogs_val = len(os.listdir(validation_dogs_dir))

total_train = num_cats_tr + num_dogs_tr
total_val = num_cats_val + num_dogs_val

print('Кошек в тестовом наборе данных: ', num_cats_tr)
print('Собак в тестовом наборе данных: ', num_dogs_tr)

print('Кошек в валидационном наборе данных: ', num_cats_val)
print('Собак в валидационном наборе данных: ', num_dogs_val)
print('--')
print('Всего изображений в тренировочном наборе данных: ', total_train)
print('Всего изображений в валидационном наборе данных: ', total_val)

"""# Установка параметров модели

Для удобства мы вынесем установку переменных, которые нам понадобятся для дальнейшей обработки данных и тренировки модели, в отдельное объявление:
"""

BATCH_SIZE = 100 # количество тренировочных изображений для обработки перед обновлением параметров модели
IMG_SHAPE = 150 # размерность к которой будет преведено входное изображение

"""# Расширение данных

Переобучение обычно происходит в тех случаях, когда в нашем наборе данных мало обучающих примеров. Один из способов устранить нехватку данных - их расширение до нужного количества экземпляров и нужной вариативностью. Расширение данных представляет собой процесс генерации данных из существующих экземпляров путём применения различных трансформаций к исходному набору данных. Целью такого метода является увеличение количества уникальных входных экземпляров, которые модель больше никогда не увидит, что, в свою очередь, позволит модели лучше обобщать входные данные и показывать большую точность на валидационном наборе данных.

С использованием **`tf.keras`** мы можем реализовать подобные случайные преобразования и генерацию новых изображений через класс **`ImageDataGenerator`**. Нам будет достаточно передать в виде параметров различные трансформации, которые мы хотели бы применить к изображениям, а обо всём остальном во время тренировки модели позаботится сам класс.

Для начала давайте напишем функцию, которая будет отображать изображения полученные в результате случайных преобразований. Затем мы подробнее разберём используемые преобразования в процессе расширения исходного набора данных.
"""

def plotImages(images_arr):
  fig, axes = plt.subplots(1, 5, figsize=(20,20))
  axes = axes.flatten()
  for img, ax in zip(images_arr, axes):
    ax.imshow(img)
  plt.tight_layout()
  plt.show()

"""#### Переворачивание изображения по горизонтали

Начать мы можем с простого преобразования - горизонтального переворачивания изображения. Посмотрим, каким образом данное преобразование будет выглядеть применённое на наших исходных изображениях. Чтобы добиться подобной трансформации необходимо передать параметр `horizontal_flip=True` конструктору класса **ImageDataGenerator**.
"""

image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))

"""Чтобы увидеть преобразование в действии давайте возьмём одно из наших изображений из обучающего набора данных и повторим его пять раз. Преобразование будет произвольным образом применено (или не будет) к каждой копии."""

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)

"""#### Поворот изображений

Преобразование в виде поворота произвольным образом повернёт изображение на определённое количество градусов. В нашем примере значение угла поворота равно 45.
"""

image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))

"""Чтобы увидеть преобразование мы поступим таким же образом - возьмём одно произвольное изображение из входного набора данных и 5 раз его повторим. Преобразование будет произвольным образом применено (или не применено) к каждой копии."""

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)

"""#### Применение увеличения

Мы так же можем применить преобразование увеличения к нашему входному набору данных - увеличить произвольно до х50%.
"""

image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))

"""Поступим так же, как поступали в прошлый раз - 5 раз повторим одно из входных изображений. Преобразование будет (или не будет) случайным образом применено к каждой копии изображения."""

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)

"""#### Объединяем всё вместе

Мы можем применить все приведённые выше преобразования, и даже больше, одной строкой кода, лишь передавая нужные аргументы с нужными значениями конструктору класса `ImageDataGenerator`.

Пора объединить все использованные ранее преобразования - изменение размеров изображения, поворот на 45 градусов, смещение по ширине, смещение по высоте, горизонтальный переворот и увеличение.
"""

image_gen_train = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,
                                                     directory=train_dir,
                                                     shuffle=True,
                                                     target_size=(IMG_SHAPE, IMG_SHAPE),
                                                     class_mode='binary')

"""Давайте визуализируем то, каким образом будут выглядеть изображения к которым будут применены произвольные преобразования."""

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImages(augmented_images)

"""#### Создаём валидационный набор данных

В основном, расширение данных применяется на обучающем наборе данных, чтобы они представляли собой репрезентативную выборку того, каким образом будут выглядеть настоящие входные данные с которыми предстоит работать модели. Поэтому к валидационному набору данных мы никаких преобразований, кроме изменения размера, не применяем.
"""

image_gen_val = ImageDataGenerator(rescale=1./255)

val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,
                                                 directory=validation_dir,
                                                 target_size=(IMG_SHAPE, IMG_SHAPE),
                                                 class_mode='binary')

"""# Создание модели

### Описываем модель

Модель состоит из 4 блоков свёртки после каждого из которых следует блок со слоем подвыборки. 

Перед последним полносвязным слоем мы так же применяем исключение со значением вероятности 0.5. Это означает, что 50% значений поступающих на вход этому слою будут сброшены до 0. Это позволит избежать переобучения.

Далее у нас идёт полносвязный слой с 512 нейронами и функцией активации `relu`. Модель выдаст распределение вероятностей по двум классам - собаки и кошки - используя `softmax`.
"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])

"""#### Компилирование модели

Как и ранее мы воспользуемся оптимизатором `adam`. В качестве функции потерь воспользуемся `sparse_categorical_crossentropy`. Так же мы хотим на каждой обучающей итерации следить за точностью модели, поэтому передаём значение `accuracy` в параметр `metrics`:
"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""#### Представление модели

Давайте взглянем на структуру нашей модели по уровням используя метод **summary**:
"""

model.summary()

"""#### Тренировка модели

Настала пора тренировки модели!

Так как обучающие блоки будут поступать из генератора (`ImageDataGenerator`) мы воспользуемся методом `fit_generator` вместо ранее используемого метода `fit`:
"""

EPOCHS = 400
history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
    epochs=EPOCHS,
    validation_data=val_data_gen,
    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))
)

"""#### Визуализация результатов тренировки

Теперь мы визуализируем результаты тренировки нашей модели:
"""

acc = history.history['acc']
val_acc = history.history['val_acc']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(EPOCHS)

plt.figure(figsize=(25,10))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Точность на обучении')
plt.plot(epochs_range, val_acc, label='Точность на валидации')
plt.legend(loc='lower right')
plt.title('Точность на обучающих и валидационных данных')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Потери на обучении')
plt.plot(epochs_range, val_loss, label='Потери на валидации')
plt.legend(loc='upper right')
plt.title('Потери на обучающих и валидационных данных')
plt.savefig('./foo.png')
plt.show()